{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import time\n",
    "import json\n",
    "import ollama\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load intents from intents.json\n",
    "def load_intents():\n",
    "    \"\"\"Load intents.json and convert them into retrievable text format.\"\"\"\n",
    "    try:\n",
    "        with open(\"data/intents.json\", \"r\") as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        intents_text = []\n",
    "        intent_lookup = {}  # Dictionary for quick lookup\n",
    "\n",
    "        for intent in data[\"intents\"]:\n",
    "            for pattern in intent[\"patterns\"]:\n",
    "                response = intent[\"responses\"][0]  # Use the first response for now\n",
    "                intents_text.append(Document(page_content=f\"Pattern: {pattern}\\nResponse: {response}\"))\n",
    "                intent_lookup[pattern.lower()] = response  # Store for direct lookup\n",
    "\n",
    "        return intents_text, intent_lookup\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error loading intents.json: {e}\")\n",
    "        return [], {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load intents\n",
    "intent_docs, intent_lookup = load_intents()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train-related intents from train_Data.json\n",
    "def load_train_intents():\n",
    "    \"\"\"Load train_Data.json and convert them into retrievable text format.\"\"\"\n",
    "    try:\n",
    "        with open(\"data/train_Data.json\", \"r\") as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        train_intents_text = []\n",
    "        for intent in data[\"intents\"]:\n",
    "            for pattern in intent[\"patterns\"]:\n",
    "                response = intent[\"responses\"][0]  # Use the first response\n",
    "                train_intents_text.append(Document(page_content=f\"Pattern: {pattern}\\nResponse: {response}\"))\n",
    "        \n",
    "        return train_intents_text\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error loading train_Data.json: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process both content.txt, intents.json, and train_Data.json into FAISS\n",
    "@st.cache_resource\n",
    "def load_faiss_index():\n",
    "    \"\"\"Loads text data from content.txt, intents.json, and train_Data.json, chunks it, embeds it, and stores it in FAISS.\"\"\"\n",
    "    try:\n",
    "        # Load content.txt\n",
    "        loader = TextLoader(\"data/content.txt\")\n",
    "        documents = loader.load()\n",
    "\n",
    "        # Split text into chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "        docs = text_splitter.split_documents(documents)\n",
    "\n",
    "        # Load train-related intents\n",
    "        train_intents_docs = load_train_intents()\n",
    "\n",
    "        # Combine all sources\n",
    "        all_docs = docs + intent_docs + train_intents_docs\n",
    "\n",
    "        # Create embeddings using Hugging Face\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "        # Store in FAISS for retrieval\n",
    "        vectorstore = FAISS.from_documents(all_docs, embeddings)\n",
    "\n",
    "        return vectorstore.as_retriever()\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error loading FAISS index: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load the FAISS retriever (runs once to cache)\n",
    "retriever = load_faiss_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream text output\n",
    "def stream_Data(text, delay: float = 0.05):\n",
    "    \"\"\"Yields words with a delay for smooth streaming.\"\"\"\n",
    "    for word in text.split():\n",
    "        yield word + \" \"\n",
    "        time.sleep(delay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check for direct intent matches\n",
    "def check_intents(user_input):\n",
    "    \"\"\"Checks if the user's query matches any predefined intents and returns a response.\"\"\"\n",
    "    user_input_lower = user_input.lower()\n",
    "    for pattern, response in intent_lookup.items():\n",
    "        if pattern in user_input_lower:\n",
    "            return response\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"üîç RAG Chatbot (General Chat + Train Queries)\")\n",
    "\n",
    "# Initial bot message\n",
    "if \"conversation_started\" not in st.session_state:\n",
    "    st.session_state.conversation_started = False\n",
    "\n",
    "if not st.session_state.conversation_started:\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        st.write(\"Hi... how can I help you today?\")\n",
    "    st.session_state.conversation_started = True\n",
    "\n",
    "# User input\n",
    "prompt = st.chat_input(\"Chat with the bot...\")\n",
    "\n",
    "if prompt:\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.write(prompt)\n",
    "\n",
    "    # Check for predefined intent matches first\n",
    "    intent_response = check_intents(prompt)\n",
    "\n",
    "    if intent_response:\n",
    "        # Respond using predefined intents\n",
    "        with st.chat_message(\"assistant\"):\n",
    "            st.write(stream_Data(intent_response))\n",
    "    else:\n",
    "        # Retrieve relevant documents for train-related queries\n",
    "        if retriever:\n",
    "            relevant_docs = retriever.get_relevant_documents(prompt)\n",
    "            context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "\n",
    "            # Construct query with retrieved context\n",
    "            full_prompt = f\"Context: {context}\\n\\nUser: {prompt}\\n\\nAnswer:\"\n",
    "\n",
    "            # Send query to TinyLlama in Ollama\n",
    "            with st.spinner(\"Processing...\"):\n",
    "                result = ollama.chat(model=\"tinyllama\", messages=[{\"role\": \"user\", \"content\": full_prompt}])\n",
    "                response = result[\"message\"][\"content\"]\n",
    "\n",
    "                # Display response\n",
    "                with st.chat_message(\"assistant\"):\n",
    "                    st.write(stream_Data(response))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
